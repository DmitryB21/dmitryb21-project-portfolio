"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/run_experiments.py --queries queries.txt --output results.json
    python scripts/run_experiments.py --query "–ö–∞–∫–æ–π SLA —É —Å–µ—Ä–≤–∏—Å–∞ –ø–ª–∞—Ç–µ–∂–µ–π?" --configs all
"""

import argparse
import json
import os
import sys
from typing import List, Dict, Any, Optional
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.storage.experiment_repository import ExperimentRepository, ExperimentConfig
from app.agent.agent import AgentController
from app.retrieval.retriever import Retriever
from app.retrieval.metadata_filter import MetadataFilter
from app.reranking.reranker import Reranker
from app.generation.prompt_builder import PromptBuilder
from app.generation.gigachat_client import LLMClient
from app.evaluation.metrics import MetricsCollector
from app.evaluation.ragas_evaluator import RAGASEvaluator
from app.ingestion.embedding_service import EmbeddingService
from qdrant_client import QdrantClient
from unittest.mock import MagicMock


def create_agent_controller_for_experiment(
    chunk_size: int,
    k: int,
    use_reranking: bool,
    embedding_dim: int = 1536
) -> AgentController:
    """
    –°–æ–∑–¥–∞—ë—Ç AgentController —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.
    
    Args:
        chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è –≤ –∫–æ–Ω—Ñ–∏–≥–µ)
        k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ retrieved –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        use_reranking: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ reranking
        embedding_dim: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤
    
    Returns:
        AgentController —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    """
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤)
    # –í production –∑–¥–µ—Å—å –±—É–¥—É—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
    qdrant_client = MagicMock()
    embedding_service = MagicMock()
    embedding_service.get_embedding.return_value = [0.0] * embedding_dim
    
    retriever = Retriever(
        qdrant_client=qdrant_client,
        embedding_service=embedding_service,
        collection_name="neuro_docs"
    )
    
    metadata_filter = MetadataFilter()
    
    reranker = Reranker() if use_reranking else None
    
    prompt_builder = PromptBuilder()
    
    llm_client = LLMClient(
        api_key=os.getenv("GIGACHAT_API_KEY", ""),
        api_url=os.getenv("GIGACHAT_API_URL", "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"),
        mock_mode=True  # –î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º mock mode
    )
    
    metrics_collector = MetricsCollector()
    ragas_evaluator = RAGASEvaluator(mock_mode=True)
    
    controller = AgentController(
        retriever=retriever,
        metadata_filter=metadata_filter,
        prompt_builder=prompt_builder,
        llm_client=llm_client,
        metrics_collector=metrics_collector,
        ragas_evaluator=ragas_evaluator,
        reranker=reranker
    )
    
    return controller


def get_experiment_configs(config_type: str = "all") -> List[Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.
    
    Args:
        config_type: –¢–∏–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π ("all", "chunk_size", "k", "reranking", "minimal")
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    """
    if config_type == "minimal":
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        return [
            {"chunk_size": 300, "k": 3, "use_reranking": False},
            {"chunk_size": 300, "k": 3, "use_reranking": True},
        ]
    
    elif config_type == "chunk_size":
        # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ —á–∞–Ω–∫–æ–≤
        return [
            {"chunk_size": 200, "k": 3, "use_reranking": False},
            {"chunk_size": 300, "k": 3, "use_reranking": False},
            {"chunk_size": 400, "k": 3, "use_reranking": False},
        ]
    
    elif config_type == "k":
        # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ K
        return [
            {"chunk_size": 300, "k": 3, "use_reranking": False},
            {"chunk_size": 300, "k": 5, "use_reranking": False},
            {"chunk_size": 300, "k": 8, "use_reranking": False},
        ]
    
    elif config_type == "reranking":
        # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å reranking
        return [
            {"chunk_size": 300, "k": 3, "use_reranking": False},
            {"chunk_size": 300, "k": 3, "use_reranking": True},
            {"chunk_size": 300, "k": 5, "use_reranking": False},
            {"chunk_size": 300, "k": 5, "use_reranking": True},
        ]
    
    else:  # "all"
        # –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        configs = []
        
        # –†–∞–∑–Ω—ã–µ chunk_size
        for chunk_size in [200, 300, 400]:
            for k in [3, 5, 8]:
                for use_reranking in [False, True]:
                    configs.append({
                        "chunk_size": chunk_size,
                        "k": k,
                        "use_reranking": use_reranking
                    })
        
        return configs


def run_experiment(
    query: str,
    config: Dict[str, Any],
    agent_controller: AgentController,
    experiment_repository: ExperimentRepository
) -> str:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π.
    
    Args:
        query: –ó–∞–ø—Ä–æ—Å –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        agent_controller: AgentController —Å –Ω—É–∂–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        experiment_repository: –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    """
    # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    experiment_config = ExperimentConfig(
        chunk_size=config["chunk_size"],
        k=config["k"],
        use_reranking=config["use_reranking"],
        embedding_model=os.getenv("EMBEDDING_MODEL_VERSION", "GigaChat-Embeddings-V1"),
        embedding_dim=int(os.getenv("EMBEDDING_DIM", "1536"))
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ AgentController
    import time
    start_time = time.time()
    
    response = agent_controller.ask(
        query=query,
        k=config["k"],
        use_reranking=config["use_reranking"]
    )
    
    end_time = time.time()
    latency_ms = (end_time - start_time) * 1000
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞
    metrics = response.metrics.copy()
    
    # –î–æ–±–∞–≤–ª—è–µ–º latency –º–µ—Ç—Ä–∏–∫–∏
    metrics["latency_ms"] = latency_ms
    metrics["retrieval_latency_ms"] = metrics.get("retrieval_latency_ms", 0)
    metrics["generation_latency_ms"] = metrics.get("generation_latency_ms", 0)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
    description = f"Query: {query[:50]}... | Config: chunk_size={config['chunk_size']}, k={config['k']}, reranking={config['use_reranking']}"
    experiment_id = experiment_repository.save_experiment(
        config=experiment_config,
        metrics=metrics,
        description=description
    )
    
    return experiment_id


def run_batch_experiments(
    queries: List[str],
    configs: List[Dict[str, Any]],
    output_file: Optional[str] = None
) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç batch —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏.
    
    Args:
        queries: –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
        output_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    """
    experiment_repository = ExperimentRepository(use_memory=True)
    experiment_ids = []
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ batch —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:")
    print(f"   - –ó–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}")
    print(f"   - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {len(configs)}")
    print(f"   - –í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {len(queries) * len(configs)}")
    print()
    
    total_experiments = len(queries) * len(configs)
    current_experiment = 0
    
    for query_idx, query in enumerate(queries, 1):
        print(f"üìù –ó–∞–ø—Ä–æ—Å {query_idx}/{len(queries)}: {query[:60]}...")
        
        for config_idx, config in enumerate(configs, 1):
            current_experiment += 1
            print(f"   ‚öôÔ∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è {config_idx}/{len(configs)}: "
                  f"chunk_size={config['chunk_size']}, k={config['k']}, "
                  f"reranking={config['use_reranking']} "
                  f"({current_experiment}/{total_experiments})")
            
            # –°–æ–∑–¥–∞—ë–º AgentController —Å –Ω—É–∂–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            agent_controller = create_agent_controller_for_experiment(
                chunk_size=config["chunk_size"],
                k=config["k"],
                use_reranking=config["use_reranking"]
            )
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
            try:
                experiment_id = run_experiment(
                    query=query,
                    config=config,
                    agent_controller=agent_controller,
                    experiment_repository=experiment_repository
                )
                experiment_ids.append(experiment_id)
                print(f"      ‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {experiment_id[:8]}...")
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        print()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    all_experiments = experiment_repository.list_experiments()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        "timestamp": datetime.now().isoformat(),
        "total_experiments": len(experiment_ids),
        "queries": queries,
        "configs": configs,
        "experiments": [
            {
                "id": exp.id,
                "config": {
                    "chunk_size": exp.config.chunk_size,
                    "k": exp.config.k,
                    "use_reranking": exp.config.use_reranking,
                    "embedding_model": exp.config.embedding_model,
                    "embedding_dim": exp.config.embedding_dim
                },
                "metrics": exp.metrics,
                "timestamp": exp.timestamp.isoformat(),
                "description": exp.description
            }
            for exp in all_experiments
        ]
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    return results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞"""
    parser = argparse.ArgumentParser(
        description="–ó–∞–ø—É—Å–∫ batch —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏"
    )
    
    parser.add_argument(
        "--query",
        type=str,
        help="–û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"
    )
    
    parser.add_argument(
        "--queries",
        type=str,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)"
    )
    
    parser.add_argument(
        "--configs",
        type=str,
        default="minimal",
        choices=["all", "minimal", "chunk_size", "k", "reranking"],
        help="–¢–∏–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (default: minimal)"
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default="experiment_results.json",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: experiment_results.json)"
    )
    
    args = parser.parse_args()
    
    # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã
    queries = []
    if args.query:
        queries = [args.query]
    elif args.queries:
        if not os.path.exists(args.queries):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.queries}")
            sys.exit(1)
        with open(args.queries, 'r', encoding='utf-8') as f:
            queries = [line.strip() for line in f if line.strip()]
    else:
        # –ó–∞–ø—Ä–æ—Å—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        queries = [
            "–ö–∞–∫–æ–π SLA —É —Å–µ—Ä–≤–∏—Å–∞ –ø–ª–∞—Ç–µ–∂–µ–π?",
            "–ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω—É–∂–Ω—ã –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –æ—Ç–ø—É—Å–∫–∞?",
            "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å VPN –¥–ª—è —É–¥–∞–ª—ë–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã?",
        ]
        print("‚ÑπÔ∏è  –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–∞–ø—Ä–æ—Å—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    if not queries:
        print("‚ùå –ù–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
        sys.exit(1)
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    configs = get_experiment_configs(args.configs)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º batch —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    results = run_batch_experiments(
        queries=queries,
        configs=configs,
        output_file=args.output
    )
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "="*60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í")
    print("="*60)
    print(f"–í—Å–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {results['total_experiments']}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {len(configs)}")
    print(f"–ó–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}")
    print()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
    if results['experiments']:
        print("üèÜ –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º:")
        for metric_name in ["precision_at_3", "faithfulness", "answer_relevancy"]:
            best_exp = max(
                results['experiments'],
                key=lambda x: x['metrics'].get(metric_name, 0),
                default=None
            )
            if best_exp and metric_name in best_exp['metrics']:
                print(f"   {metric_name}: {best_exp['metrics'][metric_name]:.3f} "
                      f"(chunk_size={best_exp['config']['chunk_size']}, "
                      f"k={best_exp['config']['k']}, "
                      f"reranking={best_exp['config']['use_reranking']})")
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")


if __name__ == "__main__":
    main()

