#!/usr/bin/env python
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ Ingestion Pipeline - –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from qdrant_client import QdrantClient
from app.ingestion.loader import DocumentLoader
from app.ingestion.chunker import Chunker
from app.ingestion.embedding_service import EmbeddingService
from app.ingestion.indexer import QdrantIndexer
from app.api.indexing_status import get_tracker
from app.storage.document_repository import DocumentRepository, DocumentMetadata

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


def main():
    """
    –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ Ingestion Pipeline:
    1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ data/NeuroDoc_Data/
    2. –ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings
    4. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant (—Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ neuro_docs, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    """
    tracker = get_tracker()
    tracker.start(total_steps=5)
    
    print("=" * 80)
    print("Neuro_Doc_Assistant - Ingestion Pipeline")
    print("=" * 80)
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (S3 –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–∞—è —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞)
    use_s3_env = os.getenv("USE_S3_STORAGE", "auto").lower()
    use_s3 = use_s3_env in ("true", "1", "yes", "auto")
    
    print(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    print(f"   USE_S3_STORAGE={use_s3_env}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö S3
    s3_endpoint = os.getenv("S3_ENDPOINT")
    s3_access_key = os.getenv("S3_ACCESS_KEY")
    s3_secret_key = os.getenv("S3_SECRET_KEY")
    s3_bucket = os.getenv("S3_BUCKET")
    
    print(f"   S3_ENDPOINT: {s3_endpoint or 'NOT SET'}")
    print(f"   S3_ACCESS_KEY: {'SET' if s3_access_key else 'NOT SET'}")
    print(f"   S3_SECRET_KEY: {'SET' if s3_secret_key else 'NOT SET'}")
    print(f"   S3_BUCKET: {s3_bucket or 'NOT SET'}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ boto3 –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è S3
    if use_s3:
        try:
            import boto3
            print(f"   ‚úÖ boto3 –¥–æ—Å—Ç—É–ø–µ–Ω: {boto3.__version__}")
        except ImportError as e:
            print(f"   ‚ùå boto3 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
            print(f"   üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ boto3: pip install boto3")
            print(f"   –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É...")
            use_s3 = False
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º loader —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º
    try:
        loader = DocumentLoader(storage_backend="auto" if use_s3 else "local")
        print(f"   ‚úÖ DocumentLoader –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {loader.storage_backend}")
        
        # –ï—Å–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–∏–ª—Å—è –∫–∞–∫ local, –Ω–æ –º—ã —Ö–æ—Ç–µ–ª–∏ S3, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—á–µ–º—É
        if loader.storage_backend == "local" and use_s3:
            print(f"   ‚ö†Ô∏è  DocumentLoader –≤—ã–±—Ä–∞–ª 'local' –≤–º–µ—Å—Ç–æ 's3'")
            if not all([s3_endpoint, s3_access_key, s3_secret_key, s3_bucket]):
                print(f"   üí° –ü—Ä–∏—á–∏–Ω–∞: –ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ S3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
                print(f"      –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {[var for var, val in [('S3_ENDPOINT', s3_endpoint), ('S3_ACCESS_KEY', s3_access_key), ('S3_SECRET_KEY', s3_secret_key), ('S3_BUCKET', s3_bucket)] if not val]}")
            elif loader.s3_storage is None:
                print(f"   üí° –ü—Ä–∏—á–∏–Ω–∞: S3 storage –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
                if hasattr(loader, '_s3_init_error'):
                    print(f"      –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {loader._s3_init_error}")
                if hasattr(loader, '_s3_list_error'):
                    print(f"      –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {loader._s3_list_error}")
                print(f"      –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
                print(f"        1. MinIO –∑–∞–ø—É—â–µ–Ω: docker ps | grep minio")
                print(f"        2. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å endpoint: curl {s3_endpoint}")
                print(f"        3. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å credentials –≤ .env")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DocumentLoader: {e}")
        import traceback
        traceback.print_exc()
        print("   –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É...")
        loader = DocumentLoader(storage_backend="local")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
    hr_dir = None
    it_dir = None
    
    if loader.storage_backend == "s3":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ S3
        print("üì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ S3 —Ö—Ä–∞–Ω–∏–ª–∏—â–µ...")
        try:
            # S3 storage —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ DocumentLoader
            if loader.s3_storage:
                all_docs = loader.s3_storage.list_documents()
                if not all_docs:
                    print("‚ö†Ô∏è  –í S3 —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                    print("   –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É...")
                    loader = DocumentLoader(storage_backend="local")
                else:
                    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ S3: {len(all_docs)}")
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                    categories = {}
                    for doc_key in all_docs:
                        category = doc_key.split('/')[0] if '/' in doc_key else "unknown"
                        categories[category] = categories.get(category, 0) + 1
                    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join([f'{k}: {v}' for k, v in sorted(categories.items())])}")
            else:
                print("‚ö†Ô∏è  S3 storage –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                print("   –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É...")
                loader = DocumentLoader(storage_backend="local")
        except Exception as e:
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å S3: {e}")
            import traceback
            traceback.print_exc()
            print("   –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É...")
            loader = DocumentLoader(storage_backend="local")
    
    if loader.storage_backend == "local":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
        data_dir = project_root / "data" / "NeuroDoc_Data"
        if not data_dir.exists():
            print(f"‚ùå –û—à–∏–±–∫–∞: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {data_dir}")
            print("   –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é data/NeuroDoc_Data/ –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã.")
            print("   –ò–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ S3 —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (USE_S3_STORAGE=true –≤ .env)")
            return 1
        
        hr_dir = data_dir / "hr"
        it_dir = data_dir / "it"
        
        if not hr_dir.exists() and not it_dir.exists():
            print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ hr/ –∏–ª–∏ it/ –≤ {data_dir}")
            return 1
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant –∫–ª–∏–µ–Ω—Ç–∞
    tracker.update_step(1, "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant", "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant...")
    print("[–®–∞–≥ 1/5] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant...")
    qdrant_url = os.getenv("QDRANT_URL")
    if not qdrant_url:
        qdrant_host = os.getenv("QDRANT_HOST", "localhost")
        qdrant_port = int(os.getenv("QDRANT_PORT", "6333"))
        qdrant_url = f"http://{qdrant_host}:{qdrant_port}"
    
    try:
        qdrant_client = QdrantClient(url=qdrant_url)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        collections = qdrant_client.get_collections()
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant —É—Å–ø–µ—à–Ω–æ: {qdrant_url}")
        tracker.update_step(1, "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant", f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ {qdrant_url}")
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant: {e}"
        print(f"‚ùå {error_msg}")
        print()
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Qdrant –∑–∞–ø—É—â–µ–Ω:")
        print("  Docker: docker run -p 6333:6333 qdrant/qdrant")
        print("  –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Qdrant –ª–æ–∫–∞–ª—å–Ω–æ")
        tracker.fail(error_msg)
        return 1
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    tracker.update_step(2, "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤", "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    print()
    print("[–®–∞–≥ 2/5] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    
    # DocumentLoader —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤—ã—à–µ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö
    # Chunker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
    chunker = Chunker()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DocumentRepository –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL
    doc_repository = None
    try:
        doc_repository = DocumentRepository()
        print("   ‚úÖ DocumentRepository –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (PostgreSQL)")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å DocumentRepository: {e}")
        print("   –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤ PostgreSQL")
    
    # –ù–∞—á–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ API)
    initial_embedding_dim = int(os.getenv("EMBEDDING_DIM", "1536"))
    gigachat_auth_key = os.getenv("GIGACHAT_AUTH_KEY")
    gigachat_scope = os.getenv("GIGACHAT_SCOPE", "GIGACHAT_API_PERS")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ mock mode
    # –ï—Å–ª–∏ auth_key –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –∏–ª–∏ mock mode –≤–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock mode
    use_mock_mode = not gigachat_auth_key or os.getenv("GIGACHAT_MOCK_MODE", "false").lower() == "true"
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (–ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ EmbeddingService)
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –µ–≥–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º
    embedding_service = EmbeddingService(
        model_version=os.getenv("EMBEDDING_MODEL_VERSION", "GigaChat"),
        embedding_dim=initial_embedding_dim,
        auth_key=gigachat_auth_key,
        scope=gigachat_scope,
        mock_mode=use_mock_mode
    )
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    actual_mode = "Mock Embeddings" if embedding_service.mock_mode else "GigaChat Embeddings API"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ –≤ —Ç—Ä–µ–∫–µ—Ä
    tracker.update_stats(embedding_mode=actual_mode)
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ —Ä–∞–±–æ—Ç—ã
    print()
    print("=" * 80)
    print("üìä –†–ï–ñ–ò–ú –†–ê–ë–û–¢–´ EMBEDDINGS")
    print("=" * 80)
    if embedding_service.mock_mode:
        print("   ‚ö†Ô∏è  –†–ï–ñ–ò–ú: Mock Embeddings")
        print("   üìù –û–ø–∏—Å–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ mock embeddings –Ω–∞ –æ—Å–Ω–æ–≤–µ MD5 hash")
        print("   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: Mock embeddings –ù–ï –æ—Ç—Ä–∞–∂–∞—é—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤!")
        if not gigachat_auth_key:
            print("   üí° –ü—Ä–∏—á–∏–Ω–∞: GIGACHAT_AUTH_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        elif os.getenv("GIGACHAT_MOCK_MODE", "false").lower() == "true":
            print("   üí° –ü—Ä–∏—á–∏–Ω–∞: GIGACHAT_MOCK_MODE=true –≤ .env —Ñ–∞–π–ª–µ")
        else:
            print("   üí° –ü—Ä–∏—á–∏–Ω–∞: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback (API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥–ø–∏—Å–∫—É)")
    else:
        print("   ‚úÖ –†–ï–ñ–ò–ú: GigaChat Embeddings API")
        print("   üìù –û–ø–∏—Å–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–π GigaChat Embeddings API")
        print(f"   üîë –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: OAuth 2.0 (scope: {gigachat_scope})")
        print(f"   üåê Endpoint: {embedding_service.api_url}")
        print(f"   ü§ñ –ú–æ–¥–µ–ª—å: Embeddings")
        print("   ‚ö†Ô∏è  –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: API –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å –ø–ª–∞—Ç–Ω—É—é –ø–æ–¥–ø–∏—Å–∫—É (402 Payment Required)")
        print("      –ü—Ä–∏ –æ—à–∏–±–∫–µ 402 —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ mock embeddings")
    print("=" * 80)
    print()
    
    collection_name = os.getenv("QDRANT_COLLECTION", "neuro_docs")
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ embedding_service (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ API)
    # –ù–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ indexer –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    indexer = QdrantIndexer(
        qdrant_client=qdrant_client,
        collection_name=collection_name,
        embedding_dim=initial_embedding_dim
    )
    print(f"‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã (collection: {collection_name}, embedding_dim: {initial_embedding_dim})")
    tracker.update_step(2, "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤", f"‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã (collection: {collection_name}, —Ä–µ–∂–∏–º: {actual_mode})")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    tracker.update_step(3, "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    print()
    print("[–®–∞–≥ 3/5] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    
    all_documents = []
    
    if loader.storage_backend == "s3":
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ S3
        print("   üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è S3 —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ hr –∏ it –¥–æ–∫—É–º–µ–Ω—Ç—ã
        categories = ["hr", "it"]
        
        for category in categories:
            try:
                print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ {category.upper()} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ S3...")
                category_documents = loader.load_documents(category + "/", category=category)
                all_documents.extend(category_documents)
                print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {category.upper()} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(category_documents)}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {category}: {e}")
    else:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
        print("   üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞")
        if hr_dir.exists():
            print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ HR –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {hr_dir}...")
            hr_documents = loader.load_documents(str(hr_dir), category="hr")
            all_documents.extend(hr_documents)
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ HR –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(hr_documents)}")
        
        if it_dir.exists():
            print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ IT –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {it_dir}...")
            it_documents = loader.load_documents(str(it_dir), category="it")
            all_documents.extend(it_documents)
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ IT –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(it_documents)}")
    
    if not all_documents:
        error_msg = "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
        print(f"‚ùå –û—à–∏–±–∫–∞: {error_msg}")
        tracker.fail(error_msg)
        return 1
    
    print(f"‚úÖ –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_documents)}")
    tracker.update_stats(documents_loaded=len(all_documents))
    tracker.update_step(3, "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_documents)}")
    
    # –ß–∞–Ω–∫–∏–Ω–≥
    tracker.update_step(4, "–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏", "–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏...")
    print()
    print("[–®–∞–≥ 4/5] –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏...")
    chunk_size = int(os.getenv("CHUNK_SIZE", "300"))
    overlap_percent = float(os.getenv("CHUNK_OVERLAP_PERCENT", "0.25"))
    
    all_chunks = []
    for i, doc in enumerate(all_documents):
        chunks = chunker.chunk_documents(
            [doc],
            chunk_size=chunk_size,
            overlap_percent=overlap_percent
        )
        all_chunks.extend(chunks)
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —á–∞–Ω–∫–∏–Ω–≥–∞
        if (i + 1) % 10 == 0 or i == len(all_documents) - 1:
            progress = 20.0 + ((i + 1) / len(all_documents)) * 20.0  # –®–∞–≥ 4: 20-40%
            tracker.update_progress(progress, f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {i + 1}/{len(all_documents)}")
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(all_chunks)} (chunk_size={chunk_size}, overlap={overlap_percent*100}%)")
    tracker.update_stats(chunks_created=len(all_chunks))
    tracker.update_step(4, "–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏", f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(all_chunks)}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings
    tracker.update_step(5, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings", f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings ({actual_mode})...")
    print()
    print("[–®–∞–≥ 5/5] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant...")
    if embedding_service.mock_mode:
        print("   ‚ö†Ô∏è  –†–µ–∂–∏–º: Mock Embeddings (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ MD5 hash)")
    else:
        print(f"   ‚úÖ –†–µ–∂–∏–º: GigaChat Embeddings API ({embedding_service.api_url})")
    print("   –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...")
    
    chunk_texts = [chunk.text for chunk in all_chunks]
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings –±–∞—Ç—á–∞–º–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    batch_size = 10
    all_embeddings = []
    total_batches = (len(chunk_texts) + batch_size - 1) // batch_size
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º time –¥–ª—è –∑–∞–¥–µ—Ä–∂–µ–∫ –ø—Ä–∏ rate limiting
    import time
    
    for batch_idx, i in enumerate(range(0, len(chunk_texts), batch_size)):
        batch = chunk_texts[i:i + batch_size]
        batch_embeddings = embedding_service.generate_embeddings(batch)
        all_embeddings.extend(batch_embeddings)
        
        # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        # (API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –¥—Ä—É–≥—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä 1024 –≤–º–µ—Å—Ç–æ 1536)
        if batch_idx == 0 and batch_embeddings and len(batch_embeddings) > 0:
            actual_dim = len(batch_embeddings[0])
            if actual_dim != initial_embedding_dim:
                print(f"   ‚ÑπÔ∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings: {actual_dim} (–æ–∂–∏–¥–∞–ª–∞—Å—å {initial_embedding_dim})")
                print(f"   ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é {actual_dim}")
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤ indexer
                indexer.embedding_dim = actual_dim
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç—Ä–µ–∫–µ—Ä–µ
                tracker.update_stats(embedding_dim=actual_dim)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings
        embeddings_progress = 40.0 + (batch_idx / total_batches) * 30.0  # –®–∞–≥ 5: 40-70%
        mode_label = "mock" if embedding_service.mock_mode else "GigaChat API"
        tracker.update_progress(
            embeddings_progress,
            f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings ({mode_label}): {min(i + batch_size, len(chunk_texts))}/{len(chunk_texts)} —á–∞–Ω–∫–æ–≤"
        )
        tracker.update_stats(embeddings_generated=len(all_embeddings))
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {min(i + batch_size, len(chunk_texts))}/{len(chunk_texts)} —á–∞–Ω–∫–æ–≤...")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limiting
        # (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ç—á)
        if batch_idx < total_batches - 1:
            time.sleep(0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ 0.5 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
    
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ embeddings: {len(all_embeddings)}")
    print(f"   üìä –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: {actual_mode}")
    
    # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant
    tracker.update_progress(70.0, f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant (–∫–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name})...")
    print()
    print(f"   –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant (–∫–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name})...")
    print("   –ö–æ–ª–ª–µ–∫—Ü–∏—è –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
    
    try:
        indexer.index_chunks(all_chunks, all_embeddings)
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        tracker.update_stats(chunks_indexed=len(all_embeddings))
        tracker.update_progress(100.0, "–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
        print(f"‚ùå {error_msg}")
        tracker.fail(error_msg)
        return 1
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ API)
    final_embedding_dim = embedding_service.embedding_dim
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL
    if doc_repository:
        print()
        print("[–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL...")
        saved_count = 0
        for doc in all_documents:
            try:
                s3_key = doc.metadata.get("s3_key") or doc.metadata.get("file_path")
                # –ï—Å–ª–∏ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ S3 –∫–ª—é—á
                if s3_key and not s3_key.startswith(("hr/", "it/", "compliance/", "onboarding/")):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –ø—É—Ç–∏
                    path_parts = s3_key.replace("\\", "/").split("/")
                    if "hr" in path_parts:
                        category_idx = path_parts.index("hr")
                        s3_key = "/".join(path_parts[category_idx:])
                    elif "it" in path_parts:
                        category_idx = path_parts.index("it")
                        s3_key = "/".join(path_parts[category_idx:])
                    elif "compliance" in path_parts:
                        category_idx = path_parts.index("compliance")
                        s3_key = "/".join(path_parts[category_idx:])
                    elif "onboarding" in path_parts:
                        category_idx = path_parts.index("onboarding")
                        s3_key = "/".join(path_parts[category_idx:])
                
                if s3_key:
                    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    doc_metadata = DocumentMetadata(
                        file_path=doc.metadata.get("file_path", ""),
                        s3_key=s3_key if s3_key.startswith(("hr/", "it/", "compliance/", "onboarding/")) else None,
                        category=doc.metadata.get("category", "unknown"),
                        filename=doc.metadata.get("filename", ""),
                        embedding_mode=actual_mode,
                        embedding_dim=final_embedding_dim,
                        metadata=doc.metadata
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
                    doc_id = doc_repository.save_document(doc_metadata)
                    
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
                    if s3_key.startswith(("hr/", "it/", "compliance/", "onboarding/")):
                        doc_repository.mark_as_indexed(s3_key, actual_mode, final_embedding_dim)
                    
                    saved_count += 1
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è {doc.metadata.get('filename', 'unknown')}: {e}")
        
        if saved_count > 0:
            print(f"   ‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ PostgreSQL: {saved_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    tracker.complete("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    print()
    print("=" * 80)
    print("‚úÖ INGESTION PIPELINE –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
    print("=" * 80)
    print()
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_documents)}")
    print(f"   - –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(all_chunks)}")
    print(f"   - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ embeddings: {len(all_embeddings)}")
    print(f"   - –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings: {final_embedding_dim}")
    print(f"   - –†–µ–∂–∏–º embeddings: {actual_mode}")
    print(f"   - –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –≤ Qdrant: {len(all_embeddings)}")
    print(f"   - –ö–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name}")
    if doc_repository:
        print(f"   - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ PostgreSQL: {saved_count if 'saved_count' in locals() else 0} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print()
    if embedding_service.mock_mode:
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã mock embeddings!")
        print("   Mock embeddings –Ω–µ –æ—Ç—Ä–∞–∂–∞—é—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤.")
        print("   –î–ª—è production —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π GigaChat Embeddings API.")
        print("   –ü–æ–¥—Ä–æ–±–Ω–µ–µ: https://developers.sber.ru/portal/products/gigachat")
    else:
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ä–µ–∞–ª—å–Ω—ã–π GigaChat Embeddings API")
    print()
    print("–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å FastAPI —Å–µ—Ä–≤–µ—Ä –∏ Streamlit UI!")
    print()
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

