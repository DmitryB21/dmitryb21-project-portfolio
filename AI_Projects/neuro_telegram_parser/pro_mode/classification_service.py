"""
–ú–æ–¥—É–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncpg
from config_utils import get_config
from pro_mode.embedding_service import embedding_service

logger = logging.getLogger(__name__)

class ClassificationService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ —Ç–µ–º–∞–º"""
    
    def __init__(self):
        self.confidence_threshold = 0.6  # –ü–æ–≤—ã—à–µ–Ω –¥–ª—è categorize_topic (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 0.6-0.7)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (sentence-transformers)
        self.classification_provider = None
        self._init_embedding_provider()
        
        # –ö–µ—à —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º
        self._topic_references_cache: Dict[int, List[float]] = {}
        self._topics_cache_timestamp: Optional[datetime] = None
        self._cache_ttl = 3600  # 1 —á–∞—Å
    
    def _init_embedding_provider(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º FRIDA –ø—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            from pro_mode.embedding_service import FRIDAEmbeddingProvider
            from config_utils import get_config
            config = get_config()
            frida_device = "cpu"
            try:
                if 'topic_modeling' in config:
                    frida_device = config['topic_modeling'].get('frida_device', 'cpu')
            except Exception:
                pass
            self.classification_provider = FRIDAEmbeddingProvider(device=frida_device)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è FRIDA –ø—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (device={frida_device})")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            # Fallback –Ω–∞ FRIDA
            from pro_mode.embedding_service import FRIDAEmbeddingProvider
            self.classification_provider = FRIDAEmbeddingProvider(device="cpu")
    
    async def _prepare_topic_references(self) -> Dict[int, List[float]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —ç—Ç–∞–ª–æ–Ω—ã —Ç–µ–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º categorize_topic (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if (self._topics_cache_timestamp and 
            (datetime.now() - self._topics_cache_timestamp).total_seconds() < self._cache_ttl):
            logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç—Ç–∞–ª–æ–Ω—ã —Ç–µ–º ({len(self._topic_references_cache)} —Ç–µ–º)")
            return self._topic_references_cache
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–º—ã –∏–∑ –ë–î
        topics = await self._get_all_topics()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        if not self.classification_provider:
            from pro_mode.embedding_service import FRIDAEmbeddingProvider
            self.classification_provider = FRIDAEmbeddingProvider(device="cpu")
        
        # –°–æ–∑–¥–∞–µ–º —ç—Ç–∞–ª–æ–Ω—ã —Å categorize_topic
        logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º —Å categorize_topic ({len(topics)} —Ç–µ–º)...")
        references = {}
        
        # –ë–∞—Ç—á–∏–Ω–≥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        batch_size = 50
        for i in range(0, len(topics), batch_size):
            batch_topics = topics[i:i + batch_size]
            topic_texts = []
            topic_ids = []
            
            for topic in batch_topics:
                topic_description = topic.get('description', '') or ''
                topic_text = f"{topic['name']} {topic_description} {' '.join(topic.get('synonyms', []) or [])}"
                topic_texts.append(topic_text)
                topic_ids.append(topic['id'])
            
            # –ö–æ–¥–∏—Ä—É–µ–º –±–∞—Ç—á —Ç–µ–º —Å categorize_topic
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                import concurrent.futures
                embedder = self.classification_provider._get_embedder()
                
                def encode_sync():
                    return embedder.encode(topic_texts, mode="categorize_topic")
                
                loop = asyncio.get_event_loop()
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    embeddings = await loop.run_in_executor(executor, encode_sync)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç—Ç–∞–ª–æ–Ω—ã
                for idx, topic_id in enumerate(topic_ids):
                    if idx < len(embeddings):
                        references[topic_id] = embeddings[idx]
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç—Ç–∞–ª–æ–Ω–∞ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–º: {e}")
                continue
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
        self._topic_references_cache = references
        self._topics_cache_timestamp = datetime.now()
        logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(references)} —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–æ)")
        
        return references
    
    async def classify_message(self, message_id: int, text: str) -> List[Dict[str, Any]]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ —Ç–µ–º–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º categorize_topic"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω—ã —Ç–µ–º (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
            topic_references = await self._prepare_topic_references()
            
            if not topic_references:
                logger.warning("–ù–µ—Ç —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                return []
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è —Å categorize_topic
            if not self.classification_provider:
                from pro_mode.embedding_service import FRIDAEmbeddingProvider
                self.classification_provider = FRIDAEmbeddingProvider(device="cpu")
            
            message_embedding = await self.classification_provider.get_embedding_for_classification(text)
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
            classifications = []
            for topic_id, topic_embedding in topic_references.items():
                similarity = self._cosine_similarity(message_embedding, topic_embedding)
                
                if similarity >= self.confidence_threshold:
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã –∏–∑ –ë–î –¥–ª—è –æ—Ç—á–µ—Ç–∞
                    topic_name = await self._get_topic_name(topic_id)
                    classifications.append({
                        'topic_id': topic_id,
                        'topic_name': topic_name or f"–¢–µ–º–∞ {topic_id}",
                        'score': similarity,
                        'method': 'categorize_topic'
                    })
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é (top-1)
            if classifications:
                classifications.sort(key=lambda x: x['score'], reverse=True)
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é, –µ—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞
                if len(classifications) > 1 and classifications[0]['score'] > 0.75:
                    classifications = [classifications[0]]
                else:
                    # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                    classifications = classifications[:1]  # –í—Å–µ —Ä–∞–≤–Ω–æ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –ë–î
            if classifications:
                await self._save_classifications(message_id, classifications)
            
            return classifications
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
            raise
    
    async def _get_topic_name(self, topic_id: int) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã –ø–æ ID"""
        try:
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            name = await conn.fetchval("SELECT name FROM topics WHERE id = $1", topic_id)
            await conn.close()
            return name
        except Exception:
            return None
    
    def invalidate_cache(self):
        """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–µ—à —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º (–≤—ã–∑—ã–≤–∞—Ç—å –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–µ–º)"""
        self._topic_references_cache.clear()
        self._topics_cache_timestamp = None
        logger.info("–ö–µ—à —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º –∏–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω")
    
    async def _get_all_topics(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–µ–º—ã –∏–∑ –ë–î"""
        try:
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            rows = await conn.fetch("""
                SELECT id, name, description, synonyms FROM topics ORDER BY name
            """)
            
            topics = []
            for row in rows:
                topics.append({
                    'id': row['id'],
                    'name': row['name'],
                    'description': row.get('description', '') or '',
                    'synonyms': row['synonyms'] or []
                })
            
            await conn.close()
            return topics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–º: {e}")
            raise
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        import numpy as np
        
        vec1_np = np.array(vec1)
        vec2_np = np.array(vec2)
        
        dot_product = np.dot(vec1_np, vec2_np)
        norm1 = np.linalg.norm(vec1_np)
        norm2 = np.linalg.norm(vec2_np)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    async def _save_classifications(self, message_id: int, classifications: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –ë–î"""
        try:
            if not classifications:
                logger.debug(f"–ù–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}")
                return
                
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            saved_count = 0
            for classification in classifications:
                try:
                    result = await conn.execute("""
                        INSERT INTO message_topics (message_id, topic_id, score, method)
                        VALUES ($1, $2, $3, $4)
                        ON CONFLICT (message_id, topic_id) DO UPDATE SET
                            score = EXCLUDED.score,
                            method = EXCLUDED.method,
                            created_at = NOW()
                    """, message_id, classification['topic_id'], classification['score'], classification['method'])
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ INSERT/UPDATE –≤—ã–ø–æ–ª–Ω–µ–Ω
                    if 'INSERT' in result or 'UPDATE' in result:
                        saved_count += 1
                        logger.debug(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: message_id={message_id}, topic_id={classification['topic_id']}, score={classification['score']:.3f}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é: message_id={message_id}, topic_id={classification['topic_id']}")
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: message_id={message_id}, topic_id={classification['topic_id']}, error={e}")
                    raise
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count}/{len(classifications)} –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}")
            await conn.close()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
            import traceback
            logger.error(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
            raise

    async def classify_recent_messages(self, limit: int = 500, threshold: float = None, 
                                     topic_ids: List[int] = None, 
                                     channel_ids: List[int] = None) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π —Å —Ç–µ–∫—Å—Ç–æ–º"""
        try:
            # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            old_threshold = None
            if threshold is not None:
                old_threshold = self.confidence_threshold
                self.confidence_threshold = threshold
            
            logger.info(f"üöÄ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ —Å –ø–æ—Ä–æ–≥–æ–º {self.confidence_threshold}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º IDs –≤ int –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏—à–ª–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
            if channel_ids:
                channel_ids = [int(cid) for cid in channel_ids]
            if topic_ids:
                topic_ids = [int(tid) for tid in topic_ids]
            
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º SQL –∑–∞–ø—Ä–æ—Å —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
            query = """
                SELECT id, text_content
                FROM messages
                WHERE text_content IS NOT NULL AND length(text_content) > 0
            """
            params = []
            param_num = 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª–∞–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if channel_ids:
                query += f" AND channel_id = ANY(${param_num})"
                params.append(channel_ids)
                param_num += 1
            
            query += f" ORDER BY published_at DESC LIMIT ${param_num}"
            params.append(limit)
            
            rows = await conn.fetch(query, *params)
            await conn.close()
            
            total_messages = len(rows)
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {total_messages}")
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã —Ç–µ–º—ã, –ø–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∏—Ö
            topics_to_check = None
            if topic_ids:
                topics_to_check = await self._get_topics_by_ids(topic_ids)
                logger.info(f"üìÇ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(topics_to_check)} —Ç–µ–º (–ø–æ ID)")
            else:
                topics_to_check = await self._get_all_topics()
                logger.info(f"üìÇ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(topics_to_check)} —Ç–µ–º (–≤—Å–µ)")

            processed = 0
            classified = 0
            errors = 0
            
            logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π...")
            
            for idx, row in enumerate(rows, 1):
                try:
                    # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è {idx}/{total_messages} (ID: {row['id']})...")
                    
                    classifications = await self._classify_message_with_topics(
                        row['id'], row['text_content'], topics_to_check
                    )
                    processed += 1
                    if classifications:
                        classified += 1
                        logger.info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ {idx} –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –≤ {len(classifications)} —Ç–µ–º(—É): {[c['topic_name'] for c in classifications]}")
                    else:
                        logger.info(f"‚ùå –°–æ–æ–±—â–µ–Ω–∏–µ {idx} –Ω–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ (–Ω–∏ –æ–¥–Ω–∞ —Ç–µ–º–∞ –Ω–µ –ø–æ–¥–æ—à–ª–∞)")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                    if idx % 10 == 0 or idx == total_messages:
                        logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {idx}/{total_messages} ({processed} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, {classified} –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ, {errors} –æ—à–∏–±–æ–∫)")
                        
                except Exception as e:
                    errors += 1
                    logger.warning(f"‚ö†Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è {row['id']} –ø—Ä–æ–ø—É—â–µ–Ω–∞: {e}")
                    import traceback
                    logger.debug(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
                    continue
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –ø–æ—Ä–æ–≥
            if old_threshold is not None:
                self.confidence_threshold = old_threshold
            
            return {
                'total_messages': total_messages,
                'processed': processed,
                'classified': classified,
                'errors': errors,
                'success_rate': (classified / processed * 100) if processed > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
            raise
    
    async def classify_all_messages_in_pipeline(self, message_ids: List[int] = None, 
                                                limit: int = None) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ä–∞–º–∫–∞—Ö –ø–∞–π–ø–ª–∞–π–Ω–∞ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–∞–º–∫–∞—Ö –ø–∞–π–ø–ª–∞–π–Ω–∞...")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —ç—Ç–∞–ª–æ–Ω—ã —Ç–µ–º (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
            topic_references = await self._prepare_topic_references()
            if not topic_references:
                logger.warning("–ù–µ—Ç —ç—Ç–∞–ª–æ–Ω–æ–≤ —Ç–µ–º –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                return {
                    'total_messages': 0,
                    'processed': 0,
                    'classified': 0,
                    'errors': 0,
                    'success_rate': 0
                }
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            if message_ids:
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                query = """
                    SELECT id, text_content
                    FROM messages
                    WHERE id = ANY($1::bigint[])
                      AND text_content IS NOT NULL 
                      AND length(text_content) > 10
                """
                rows = await conn.fetch(query, message_ids)
            else:
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                query = """
                    SELECT id, text_content
                    FROM messages
                    WHERE text_content IS NOT NULL 
                      AND length(text_content) > 10
                    ORDER BY published_at DESC
                """
                if limit:
                    query += f" LIMIT {limit}"
                rows = await conn.fetch(query)
            
            await conn.close()
            
            total_messages = len(rows)
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {total_messages}")
            
            if total_messages == 0:
                return {
                    'total_messages': 0,
                    'processed': 0,
                    'classified': 0,
                    'errors': 0,
                    'success_rate': 0
                }
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            if not self.classification_provider:
                from pro_mode.embedding_service import FRIDAEmbeddingProvider
                self.classification_provider = FRIDAEmbeddingProvider(device="cpu")
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º –∑–∞—Ä–∞–Ω–µ–µ (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–µ–º...")
            topic_names_cache = {}
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            try:
                topic_ids_list = list(topic_references.keys())
                if topic_ids_list:
                    rows_topics = await conn.fetch(
                        "SELECT id, name FROM topics WHERE id = ANY($1::int[])",
                        topic_ids_list
                    )
                    for row in rows_topics:
                        topic_names_cache[row['id']] = row['name']
            finally:
                await conn.close()
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            for topic_id in topic_references.keys():
                if topic_id not in topic_names_cache:
                    topic_names_cache[topic_id] = f"–¢–µ–º–∞ {topic_id}"
            
            processed = 0
            classified = 0
            errors = 0
            
            # –ë–∞—Ç—á–∏–Ω–≥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            batch_size = 50
            for i in range(0, len(rows), batch_size):
                batch = rows[i:i + batch_size]
                batch_texts = [row['text_content'] for row in batch]
                batch_ids = [row['id'] for row in batch]
                
                try:
                    # –ö–æ–¥–∏—Ä—É–µ–º –±–∞—Ç—á —Å–æ–æ–±—â–µ–Ω–∏–π —Å categorize_topic
                    import concurrent.futures
                    embedder = self.classification_provider._get_embedder()
                    
                    def encode_sync():
                        return embedder.encode(batch_texts, mode="categorize_topic")
                    
                    loop = asyncio.get_event_loop()
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        message_embeddings = await loop.run_in_executor(executor, encode_sync)
                    
                    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏ —Ç–µ–º
                    for idx, (message_id, message_embedding) in enumerate(zip(batch_ids, message_embeddings)):
                        try:
                            classifications = []
                            for topic_id, topic_embedding in topic_references.items():
                                similarity = self._cosine_similarity(message_embedding, topic_embedding)
                                
                                if similarity >= self.confidence_threshold:
                                    classifications.append({
                                        'topic_id': topic_id,
                                        'topic_name': topic_names_cache.get(topic_id, f"–¢–µ–º–∞ {topic_id}"),
                                        'score': similarity,
                                        'method': 'categorize_topic'
                                    })
                            
                            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
                            if classifications:
                                classifications.sort(key=lambda x: x['score'], reverse=True)
                                if len(classifications) > 1 and classifications[0]['score'] > 0.75:
                                    classifications = [classifications[0]]
                                else:
                                    classifications = classifications[:1]
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
                                await self._save_classifications(message_id, classifications)
                                classified += 1
                            
                            processed += 1
                            
                        except Exception as e:
                            errors += 1
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
                            continue
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    if (i + batch_size) % 100 == 0 or (i + batch_size) >= len(rows):
                        logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {min(i + batch_size, len(rows))}/{len(rows)} "
                                  f"({processed} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, {classified} –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ, {errors} –æ—à–∏–±–æ–∫)")
                
                except Exception as e:
                    errors += len(batch)
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
                    continue
            
            success_rate = (classified / processed * 100) if processed > 0 else 0
            logger.info(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {processed} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, {classified} –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ, "
                       f"{errors} –æ—à–∏–±–æ–∫ (—É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}%)")
            
            return {
                'total_messages': total_messages,
                'processed': processed,
                'classified': classified,
                'errors': errors,
                'success_rate': success_rate
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            raise
            
            result = {
                'processed': processed,
                'classified': classified,
                'errors': errors,
                'limit': limit,
                'total_found': total_messages
            }
            
            logger.info(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}, –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {classified}, –û—à–∏–±–æ–∫: {errors}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            import traceback
            logger.error(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
            raise
    
    async def _get_topics_by_ids(self, topic_ids: List[int]) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–º—ã –ø–æ ID"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º IDs –≤ int –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏—à–ª–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
            if topic_ids:
                topic_ids = [int(tid) for tid in topic_ids]
            
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            rows = await conn.fetch("""
                SELECT id, name, description, synonyms FROM topics WHERE id = ANY($1) ORDER BY name
            """, topic_ids)
            
            topics = []
            for row in rows:
                topics.append({
                    'id': row['id'],
                    'name': row['name'],
                    'description': row.get('description', '') or '',
                    'synonyms': row['synonyms'] or []
                })
            
            await conn.close()
            return topics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–º –ø–æ ID: {e}")
            raise
    
    async def _classify_message_with_topics(self, message_id: int, text: str, 
                                            topics: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç categorize_topic)"""
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            text_clean = text.strip()
            if not text_clean or len(text_clean) < 10:
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–ª–∏ –ø—É—Å—Ç–æ–µ")
                return []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞)
            if text_clean.startswith('@') and len(text_clean.split()) <= 1:
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id}: —Å–ª—É–∂–µ–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
                return []
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º categorize_topic –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            return await self.classify_message(message_id, text_clean)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
            import traceback
            logger.error(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
            return []

class OnboardingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    
    async def save_user_preferences(self, user_id: str, selected_topics: List[int], 
                                  seed_channels: List[int]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            await conn.execute("""
                INSERT INTO user_preferences (user_id, selected_topics, seed_channels)
                VALUES ($1, $2, $3)
                ON CONFLICT (user_id) DO UPDATE SET
                    selected_topics = EXCLUDED.selected_topics,
                    seed_channels = EXCLUDED.seed_channels,
                    updated_at = NOW()
            """, user_id, selected_topics, seed_channels)
            
            await conn.close()
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return False
    
    async def get_user_preferences(self, user_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            row = await conn.fetchrow("""
                SELECT * FROM user_preferences WHERE user_id = $1
            """, user_id)
            
            await conn.close()
            
            if row:
                return {
                    'user_id': row['user_id'],
                    'selected_topics': row['selected_topics'] or [],
                    'seed_channels': row['seed_channels'] or [],
                    'blacklisted_topics': row['blacklisted_topics'] or [],
                    'notification_settings': row['notification_settings'] or {},
                    'created_at': row['created_at'],
                    'updated_at': row['updated_at']
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return None
    
    async def get_recommended_channels(self, user_id: str, limit: int = 20) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π"""
        try:
            preferences = await self.get_user_preferences(user_id)
            if not preferences or not preferences['selected_topics']:
                return []
            
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–∞–Ω–∞–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –ø—É–±–ª–∏–∫—É—é—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º
            query = """
                SELECT c.id, c.name, c.description, c.username,
                       COUNT(DISTINCT m.id) as message_count,
                       AVG(mt.score) as avg_topic_score
                FROM channels c
                JOIN messages m ON c.id = m.channel_id
                JOIN message_topics mt ON m.id = mt.message_id
                WHERE mt.topic_id = ANY($1::integer[])
                  AND (CASE WHEN cardinality($2::bigint[]) > 0 THEN c.id NOT IN (SELECT unnest($2::bigint[])) ELSE TRUE END)
                GROUP BY c.id, c.name, c.description, c.username
                HAVING COUNT(DISTINCT m.id) >= 5
                ORDER BY avg_topic_score DESC, message_count DESC
                LIMIT $3
            """
            
            rows = await conn.fetch(query, preferences['selected_topics'], 
                                  preferences['seed_channels'], limit)
            
            recommendations = []
            for row in rows:
                recommendations.append({
                    'id': row['id'],
                    'name': row['name'],
                    'description': row['description'],
                    'username': row['username'],
                    'message_count': row['message_count'],
                    'avg_topic_score': float(row['avg_topic_score'])
                })
            
            await conn.close()
            return recommendations
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∫–∞–Ω–∞–ª–æ–≤: {e}")
            return []
    
    async def validate_channel(self, channel_identifier: str) -> Optional[Dict[str, Any]]:
        """–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"""
        try:
            config = get_config()
            conn = await asyncpg.connect(dsn=config['postgresql']['dsn'])
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ username –∏–ª–∏ ID
            row = await conn.fetchrow("""
                SELECT id, name, description, username FROM channels 
                WHERE username = $1 OR id = $1::bigint
            """, channel_identifier)
            
            await conn.close()
            
            if row:
                return {
                    'id': row['id'],
                    'name': row['name'],
                    'description': row['description'],
                    'username': row['username']
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞–Ω–∞–ª–∞: {e}")
            return None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã —Å–µ—Ä–≤–∏—Å–æ–≤
classification_service = ClassificationService()
onboarding_service = OnboardingService()
